import streamlit as st
import pandas as pd
import numpy as np
import io

st.title("æ¸©æ¹¿åº¦ãƒ‡ãƒ¼ã‚¿æ•´ç†ã‚¢ãƒ—ãƒªï¼ˆ30åˆ†ä¸¸ã‚ & ãƒ­ã‚¬ãƒ¼åä¿æŒï¼‰")

uploaded_files = st.file_uploader(
    "æœˆã”ã¨ã®ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¤‡æ•°é¸æŠã—ã¦ãã ã•ã„",
    type=["xlsx"],
    accept_multiple_files=True
)

if not uploaded_files:
    st.stop()

all_merged = []

for file in uploaded_files:
    st.write(f"---\n### ğŸ“„ èª­ã¿è¾¼ã¿ï¼š{file.name}")

    # Streamlit UploadedFile ã‚’ BytesIO ã«æ¸¡ã—ã¦èª­ã¿è¾¼ã¿
    bytes_data = file.read()
    df = pd.read_excel(io.BytesIO(bytes_data), header=1)  # header è¡Œã‚’å¿…è¦ã«å¿œã˜ã¦èª¿æ•´

    cols = df.columns.tolist()
    st.write("åˆ—åç¢ºèª:", cols)

    # Date/Time åˆ—ã®ä½ç½®ã‚’è‡ªå‹•æ¤œå‡º
    time_positions = [i for i, c in enumerate(cols) if "Date" in str(c) or "Time" in str(c)]
    if len(time_positions) < 2:
        st.warning(f"{file.name}: 2ã¤ç›®ã® Date/Time åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        continue

    hum_start, tem_start = time_positions[0], time_positions[1]

    hum_cols = cols[hum_start:tem_start]
    tem_cols = cols[tem_start:]

    hum_block = df[hum_cols].copy()
    tem_block = df[tem_cols].copy()

    st.write(f"æ¹¿åº¦ãƒ–ãƒ­ãƒƒã‚¯ shape: {hum_block.shape}")
    st.write(f"æ¸©åº¦ãƒ–ãƒ­ãƒƒã‚¯ shape: {tem_block.shape}")

    # longåŒ–
    hum_long = hum_block.melt(id_vars=[hum_cols[0]], var_name="Logger", value_name="Hum")
    tem_long = tem_block.melt(id_vars=[tem_cols[0]], var_name="Logger", value_name="Temp")

    # Time åˆ—åã‚’çµ±ä¸€
    hum_long = hum_long.rename(columns={hum_cols[0]: "Time"})
    tem_long = tem_long.rename(columns={tem_cols[0]: "Time"})

    # NaNå‰Šé™¤
    hum_long = hum_long.dropna(subset=["Hum"])
    tem_long = tem_long.dropna(subset=["Temp"])

    hum_long["Time"] = pd.to_datetime(hum_long["Time"], errors="coerce")
    tem_long["Time"] = pd.to_datetime(tem_long["Time"], errors="coerce")
    hum_long = hum_long.dropna(subset=["Time"])
    tem_long = tem_long.dropna(subset=["Time"])

    # Loggeråæ­£è¦åŒ–ï¼ˆå…ƒåˆ—åãƒ™ãƒ¼ã‚¹ã§ .1 ã‚’é™¤å»ã—ã¦æƒãˆã‚‹ï¼‰
    def normalize_logger(x):
        return str(x).replace(".1","").strip().lower().replace(" ", "")

    hum_long["Logger_norm"] = hum_long["Logger"].apply(normalize_logger)
    tem_long["Logger_norm"] = tem_long["Logger"].apply(normalize_logger)

    # 30åˆ†ä¸¸ã‚
    hum_long["Time30"] = hum_long["Time"].dt.floor("30min")
    tem_long["Time30"] = tem_long["Time"].dt.floor("30min")

    # å¹³å‡åŒ–
    hum_grp = hum_long.groupby(["Logger_norm", "Time30"], as_index=False)["Hum"].mean()
    tem_grp = tem_long.groupby(["Logger_norm", "Time30"], as_index=False)["Temp"].mean()

    # æ¹¿åº¦ã¨æ¸©åº¦ã‚’ãƒãƒ¼ã‚¸
    merged = pd.merge(hum_grp, tem_grp, on=["Logger_norm", "Time30"], how="inner")
    merged["SourceFile"] = file.name

    # å…ƒã® Logger åã‚‚æ®‹ã™
    merged["Logger"] = merged["Logger_norm"]

    st.write(f"ãƒãƒ¼ã‚¸çµæœ shape: {merged.shape}")
    all_merged.append(merged)

# å…¨ãƒ•ã‚¡ã‚¤ãƒ«çµåˆ
if all_merged:
    final_df = pd.concat(all_merged, ignore_index=True)
    st.write("### ğŸ‰ å…¨ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆçµæœ")
    st.write(final_df)

    csv = final_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        label="ğŸ“¥ CSV ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv,
        file_name="merged_THdata.csv",
        mime="text/csv"
    )
else:
    st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
