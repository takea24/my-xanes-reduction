import streamlit as st
import pandas as pd
import numpy as np
import io

st.title("æ¸©æ¹¿åº¦ãƒ‡ãƒ¼ã‚¿æ•´ç†ã‚¢ãƒ—ãƒªï¼ˆ30åˆ†ä¸¸ã‚ & ãƒ­ã‚¬ãƒ¼åå…ƒåˆ—åä¿æŒï¼‰")

uploaded_files = st.file_uploader(
    "æœˆã”ã¨ã®ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¤‡æ•°é¸æŠã—ã¦ãã ã•ã„",
    type=["xlsx"],
    accept_multiple_files=True
)

if not uploaded_files:
    st.stop()

all_merged = []

for file in uploaded_files:
    st.write(f"---\n### ğŸ“„ èª­ã¿è¾¼ã¿ï¼š{file.name}")

    # åˆ—åã®è‡ªå‹•å¤‰æ›´ã‚’é˜²ã
    df = pd.read_excel(io.BytesIO(file.read()), header=1)
    cols = df.columns.tolist()
    st.write("åˆ—å:", cols)

    # Date/Time åˆ—ã®ä½ç½®ã‚’æ¤œå‡º
    time_positions = [i for i, c in enumerate(cols) if "Date" in str(c) or "Time" in str(c)]
    if len(time_positions) < 2:
        st.error("2ã¤ç›®ã® Date/Time åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        continue  # å•é¡Œã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—

    hum_start = time_positions[0]
    tem_start = time_positions[1]

    hum_cols = cols[hum_start:tem_start]
    tem_cols = cols[tem_start:]

    hum_block = df[hum_cols].copy()
    tem_block = df[tem_cols].copy()

    st.write(f"æ¹¿åº¦ãƒ–ãƒ­ãƒƒã‚¯ shape: {hum_block.shape}")
    st.write(f"æ¸©åº¦ãƒ–ãƒ­ãƒƒã‚¯ shape: {tem_block.shape}")

    # longåŒ–ï¼ˆLoggeråã¯å…ƒã®åˆ—åã‚’ä½¿ç”¨ï¼‰
    hum_long = hum_block.melt(id_vars=[hum_cols[0]], var_name="Logger", value_name="Hum")
    tem_long = tem_block.melt(id_vars=[tem_cols[0]], var_name="Logger", value_name="Temp")

    # Timeåˆ—åã‚’çµ±ä¸€
    hum_long = hum_long.rename(columns={hum_cols[0]: "Time"})
    tem_long = tem_long.rename(columns={tem_cols[0]: "Time"})

    # NaNå‰Šé™¤
    hum_long = hum_long.dropna(subset=["Hum"])
    tem_long = tem_long.dropna(subset=["Temp"])

    hum_long["Time"] = pd.to_datetime(hum_long["Time"], errors="coerce")
    tem_long["Time"] = pd.to_datetime(tem_long["Time"], errors="coerce")

    hum_long = hum_long.dropna(subset=["Time"])
    tem_long = tem_long.dropna(subset=["Time"])

    # Loggeråæ­£è¦åŒ–ï¼ˆæ¯”è¼ƒç”¨ï¼‰
    def normalize(x):
        return str(x).strip().lower().replace(" ", "").replace("_", "")

    hum_long["Logger_norm"] = hum_long["Logger"].apply(normalize)
    tem_long["Logger_norm"] = tem_long["Logger"].apply(normalize)

    # 30åˆ†ä¸¸ã‚
    hum_long["Time30"] = hum_long["Time"].dt.floor("30min")
    tem_long["Time30"] = tem_long["Time"].dt.floor("30min")

    # å¹³å‡åŒ–
    hum_grp = hum_long.groupby(["Logger_norm", "Time30"], as_index=False)["Hum"].mean()
    tem_grp = tem_long.groupby(["Logger_norm", "Time30"], as_index=False)["Temp"].mean()

    # æ¹¿åº¦ã¨æ¸©åº¦ã‚’ãƒãƒ¼ã‚¸
    merged = pd.merge(hum_grp, tem_grp, on=["Logger_norm", "Time30"], how="inner")
    merged["SourceFile"] = file.name

    # å…ƒã®Loggeråã‚‚æ®‹ã™ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    merged["Logger"] = merged["Logger_norm"]

    st.write("ãƒãƒ¼ã‚¸çµæœ shape:", merged.shape)
    all_merged.append(merged)

# å…¨çµåˆ
if all_merged:
    final_df = pd.concat(all_merged, ignore_index=True)
    st.write("### ğŸ‰ å…¨ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆçµæœ")
    st.write(final_df)

    csv = final_df.to_csv(index=False).encode("utf-8-sig")

    st.download_button(
        label="ğŸ“¥ CSV ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv,
        file_name="merged_THdata.csv",
        mime="text/csv"
    )
else:
    st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
